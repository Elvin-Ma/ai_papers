# T5: Text-to-Text Transfer Transformer

0. Abstract
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;迁移学习是一种在自然语言处理中强大的技术，模型首先要针对数据丰富的任务进行预训练，然后再针对下游任务进行微调。本文通过引入统一的框架来探索NLP迁移学习技术的前景：将问题都转换为 text-to-text 格式，并在数十种语言理解任务研究比较了预训练目标，架构，未标记的数据集，迁移方法和其他因素。结合实验所得以及 C4 数据集，在许多基准上获得了最新的结果，这些基准涵盖了摘要，问题回答，文本分类等等。<br>

