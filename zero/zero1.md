# ZeRO：面向训练万亿参数模型的内存优化

# 摘要
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;大型深度学习模型提供了显著的准确性提升，但训练数十亿到数万亿参数是具有挑战性的。现有的解决方案，如数据并行和模型并行，在将这些模型适应有限设备内存方面存在根本的限制，同时也无法实现计算、通信和开发的高效性。我们开发了一种新的解决方案，Zero Redundancy Optimizer（ZeRO），用于优化内存，大大提高训练速度，并增加可以高效训练的模型规模。ZeRO在数据并行和模型并行训练中消除了内存冗余，同时保持低通信量和高计算粒度，使我们能够将模型规模与设备数量成比例地扩展，并保持持续的高效性。我们对内存需求和通信量的分析表明：ZeRO有潜力在现有硬件上扩展到超过1万亿个参数的规模。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们实现并评估了ZeRO：它在400个GPU上以超线性的加速度训练超过1000亿参数的大型模型，实现了15 Petaflops的吞吐量。这代表了模型规模增加了8倍，性能提升了10倍，达到了最先进水平。从可用性的角度来看，ZeRO可以训练多达130亿参数的大型模型（例如，比Megatron GPT 8.3B和T5 11B还要大），而无需使用对科研人员来说更难应用的模型并行(model parallel)技术。最后但同样重要的是，研究人员利用ZeRO的系统突破创造了世界上最大的语言模型（170亿参数），并且取得了创纪录的准确性。<br>
# 1. 扩展介绍
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;深度学习模型正在变得越来越大，而模型规模的增加带来了显著的准确性提升。在自然语言处理（NLP）领域，Transformer模型为Bert-large（0.3B）[1]、GPT-2（1.5B）[2]、Megatron-LM（8.3B）[3]、T5（11B）[4]等大型模型铺平了道路。为了实现模型规模从数十亿到数万亿参数的持续增长，我们面临着训练这些模型的挑战 - 它们显然无法适应单个设备（例如GPU或TPU）的内存，而仅仅增加更多设备也无法帮助扩展训练。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;基本的数据并行（DP）不能减少每个设备的内存占用，在当前一代具有32 GB内存的GPU上，对于1.4B以上参数的模型，内存会耗尽。其他现有的解决方案，如管道并行（PP）、模型并行（MP）、CPU卸载等，在功能、可用性以及内存、计算/通信效率之间做出了权衡(trade-offs)，而这些都对于实现高速度和大规模训练至关重要。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在训练大型模型的不同现有解决方案中，模型并行（Model Parallel）可能是最有前景的。目前文献中最大的模型，包括11B的T5模型[4]和8.3B的Megatron-LM模型[3]，都是通过模型并行(model parallel)实现的，分别使用了Mesh-Tensorflow[5]和Megatron-LM[3]。然而，模型并行在这些模型规模之外的扩展性有限。模型并行将模型垂直划分，将每层的计算和参数分配到多个设备中，需要在每层之间进行大量的通信。因此，在GPU之间的通信带宽较高的单个节点内，它们可以很好地工作，但在超过单个节点之后，效率会迅速降低[3]。我们使用Megatron-LM在两个DGX-2节点上测试了一个具有40B参数的模型，并观察到每个V100 GPU的性能约为5 T flops（不到硬件峰值的5%）。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;那么，我们如何克服现有解决方案的限制，更高效地训练大型模型呢？为了回答这个问题，我们首先分析了现有系统在模型训练中的内存消耗的全景(full spectrum)，并将其分为两个部分：1）对于大型模型，大部分内存被模型状态(model states)所占用，包括优化器状态（如Adam中的动量和方差[6]）、梯度和参数。2）剩余的内存被激活值、临时缓冲区和不可用的碎片化内存所消耗，我们统称为残余状态(residual states)。我们开发了Zero Redundancy Optimizer（ZeRO）来同时优化这两部分的内存效率，并实现高计算和通信效率。由于这两个部分面临不同的挑战，我们相应地开发和讨论它们的解决方案。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**优化模型状态内存**:在训练过程中，模型状态通常占用最多的内存，但是现有的方法如数据并行（DP）和模型并行（MP）并没有提供令人满意的解决方案。DP在计算/通信效率方面表现良好，但在内存效率方面较差，而MP可能在计算/通信效率方面表现较差。具体而言，DP在所有数据并行进程中复制整个模型状态，导致冗余的内存消耗；而MP通过对这些状态进行分区以获得较高的内存效率，但通常会导致过于细粒度的计算和昂贵的通信，从而降低了扩展效率。此外，所有这些方法都静态地保留了整个训练过程中所需的所有模型状态，即使在训练过程中并不始终需要所有模型状态。基于这些观察结果，我们开发了ZeRO-DP，即基于ZeRO的数据并行方法，它既实现了DP的计算/通信效率，又实现了MP的内存效率。ZeRO-DP**通过对模型状态进行分区而不是复制**来消除数据并行进程中的内存状态冗余，并通过在训练过程中使用**动态通信调度**来保持DP的计算粒度和通信量，从而保持了计算/通信效率。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ZeRO-DP有三个主要的优化阶段（如图1所示），分别对应于优化器状态、梯度和参数的分区(partitioning)。如下分类，这些阶段被渐进地启用：
1. 优化器状态分区( $P_{os}$ )：内存减少4倍，与DP相同的通信量；
2. 添加梯度分区( $P_{os+g}$ )：内存减少8倍，与DP相同的通信量；
3. 添加参数分区( $P_{os+g+p}$ )：内存减少与DP的数量 $N_{d}$ 线性相关。例如，将其分割成64个GPU( $N_{d} = 64$ )，将使内存减少64倍。通信量略有增加，约为50%。<br>
*注释：os: optimizer state; g: gradient; p: parameter*<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ZeRO-DP消除了内存冗余，并使整个集群的完整聚合内存容量可用。在启用了所有三个阶段的情况下，ZeRO可以在仅使用1024个NVIDIA GPU上训练一万亿参数的模型。带有Adam [6]等优化器的一万亿参数模型在16位精度下需要大约16太字节（TB）的内存来存储优化器状态、梯度和参数。16TB除以1024等于16GB，这在GPU上是一个合理的范围内（例如，具有32GB的设备内存）。<br>

![figure1](images/zero1_figure1.jpg)

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在ZeRO-DP提升了模型状态的内存效率之后，由激活值、临时缓冲区和无法使用的内存碎片所消耗的剩余内存可能成为次要的内存瓶颈。为了优化这三个因素所消耗的剩余内存，我们开发了ZeRO-R。<br>
1. 对于激活值（在前向传播中存储以进行反向传播），我们注意到检查点技术（checkpointing）有所帮助，但对于大型模型仍然不足。因此，ZeRO-R通过激活值分区(partitioning)来优化激活值内存，通过识别并消除现有模型并行（MP）方法中的激活值复制。当适当时，它还将激活值转移到CPU上进行处理。
2. ZeRO-R为临时缓冲区定义了适当的大小，以在内存和计算效率之间取得平衡。
3. 我们观察到在训练过程中存在着内存碎片化，这是由于不同张量的生命周期变化导致的。由于碎片化导致的非连续内存可能导致内存分配失败，即使有足够的空闲内存。ZeRO-R根据张量的不同生命周期主动管理内存，防止内存碎片化。<br>
ZeRO-DP和ZeRO-R的结合共同形成了一种强大的深度学习训练内存优化系统，我们统称为ZeRO。

**ZeRO和MP（模型并行）**：由于ZeRO消除了DP中的内存效率问题，自然而然地会问：我们是否仍然需要MP，以及何时需要？ZeRO如何与MP协同工作？使用ZeRO后，MP在仅用于适应大型模型方面变得不再那么吸引人。在减少每个设备内存占用方面，ZeRO-DP至少与MP一样有效，有时甚至比MP更有效，尤其是当MP无法均匀分割模型时。它还具有可比较或更好的扩展效率。此外，数据并行性非常易于使用，适用于不同的工作负载，而现今的MP方法通常需要模型开发人员对模型进行修改，系统开发人员解决分布式算子的问题，而现有的工作如Megatron-LM仅支持有限的算子和模型。

![figure2](images/zero1_figure2.jpg)

话虽如此，仍然存在一些情况我们希望利用MP（模型并行）：
1. 当与ZeRO-R结合使用时，MP可以减少非常大模型的激活值内存占用。
2. 对于较小的模型，激活值内存不是一个问题，但当仅使用DP时聚合批量大小过大以至于无法获得良好的收敛性时，MP也可以带来好处。<br>
在这些情况下，可以将ZeRO与MP结合使用，以适应具有可接受的聚合批量大小的模型。

