# ZeRO：面向训练万亿参数模型的内存优化

# 摘要
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;大型深度学习模型提供了显著的准确性提升，但训练数十亿到数万亿参数是具有挑战性的。现有的解决方案，如数据并行和模型并行，在将这些模型适应有限设备内存方面存在根本的限制，同时也无法实现计算、通信和开发的高效性。我们开发了一种新的解决方案，Zero Redundancy Optimizer（ZeRO），用于优化内存，大大提高训练速度，并增加可以高效训练的模型规模。ZeRO在数据并行和模型并行训练中消除了内存冗余，同时保持低通信量和高计算粒度，使我们能够将模型规模与设备数量成比例地扩展，并保持持续的高效性。我们对内存需求和通信量的分析表明：ZeRO有潜力在现有硬件上扩展到超过1万亿个参数的规模。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们实现并评估了ZeRO：它在400个GPU上以超线性的加速度训练超过1000亿参数的大型模型，实现了15 Petaflops的吞吐量。这代表了模型规模增加了8倍，性能提升了10倍，达到了最先进水平。从可用性的角度来看，ZeRO可以训练多达130亿参数的大型模型（例如，比Megatron GPT 8.3B和T5 11B还要大），而无需使用对科研人员来说更难应用的模型并行(model parallel)技术。最后但同样重要的是，研究人员利用ZeRO的系统突破创造了世界上最大的语言模型（170亿参数），并且取得了创纪录的准确性。<br>
# 1. 扩展介绍
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;深度学习模型正在变得越来越大，而模型规模的增加带来了显著的准确性提升。在自然语言处理（NLP）领域，Transformer模型为Bert-large（0.3B）[1]、GPT-2（1.5B）[2]、Megatron-LM（8.3B）[3]、T5（11B）[4]等大型模型铺平了道路。为了实现模型规模从数十亿到数万亿参数的持续增长，我们面临着训练这些模型的挑战 - 它们显然无法适应单个设备（例如GPU或TPU）的内存，而仅仅增加更多设备也无法帮助扩展训练。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;基本的数据并行（DP）不能减少每个设备的内存占用，在当前一代具有32 GB内存的GPU上，对于1.4B以上参数的模型，内存会耗尽。其他现有的解决方案，如管道并行（PP）、模型并行（MP）、CPU卸载等，在功能、可用性以及内存、计算/通信效率之间做出了权衡(trade-offs)，而这些都对于实现高速度和大规模训练至关重要。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在训练大型模型的不同现有解决方案中，模型并行（Model Parallel）可能是最有前景的。目前文献中最大的模型，包括11B的T5模型[4]和8.3B的Megatron-LM模型[3]，都是通过模型并行(model parallel)实现的，分别使用了Mesh-Tensorflow[5]和Megatron-LM[3]。然而，模型并行在这些模型规模之外的扩展性有限。模型并行将模型垂直划分，将每层的计算和参数分配到多个设备中，需要在每层之间进行大量的通信。因此，在GPU之间的通信带宽较高的单个节点内，它们可以很好地工作，但在超过单个节点之后，效率会迅速降低[3]。我们使用Megatron-LM在两个DGX-2节点上测试了一个具有40B参数的模型，并观察到每个V100 GPU的性能约为5 T flops（不到硬件峰值的5%）。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;那么，我们如何克服现有解决方案的限制，更高效地训练大型模型呢？为了回答这个问题，我们首先分析了现有系统在模型训练中的内存消耗的全景(full spectrum)，并将其分为两个部分：1）对于大型模型，大部分内存被模型状态(model states)所占用，包括优化器状态（如Adam中的动量和方差[6]）、梯度和参数。2）剩余的内存被激活值、临时缓冲区和不可用的碎片化内存所消耗，我们统称为残余状态(residual states)。我们开发了Zero Redundancy Optimizer（ZeRO）来同时优化这两部分的内存效率，并实现高计算和通信效率。由于这两个部分面临不同的挑战，我们相应地开发和讨论它们的解决方案。<br>
**优化模型状态内存**:在训练过程中，模型状态通常占用最多的内存，但是现有的方法如数据并行（DP）和模型并行（MP）并没有提供令人满意的解决方案。DP在计算/通信效率方面表现良好，但在内存效率方面较差，而MP可能在计算/通信效率方面表现较差。具体而言，DP在所有数据并行进程中复制整个模型状态，导致冗余的内存消耗；而MP通过对这些状态进行分区以获得较高的内存效率，但通常会导致过于细粒度的计算和昂贵的通信，从而降低了扩展效率。此外，所有这些方法都静态地保留了整个训练过程中所需的所有模型状态，即使在训练过程中并不始终需要所有模型状态。基于这些观察结果，我们开发了ZeRO-DP，即基于ZeRO的数据并行方法，它既实现了DP的计算/通信效率，又实现了MP的内存效率。ZeRO-DP**通过对模型状态进行分区而不是复制**来消除数据并行进程中的内存状态冗余，并通过在训练过程中使用**动态通信调度**来保持DP的计算粒度和通信量，从而保持了计算/通信效率。<br>


