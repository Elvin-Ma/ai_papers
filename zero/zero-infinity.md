# zero-infinity：打破极端规模(scale)深度学习模型的内存墙

# 摘要
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在过去的三年里，最大的密集(dense)深度学习模型的规模增长了1000倍以上，达到了数千亿个参数，而GPU内存只增长了5倍（从16GB到80GB）。因此，模型规模的增长主要是通过系统创新来支持的，这些创新使得大型模型可以适应多个GPU的总体内存。然而，我们正在接近GPU内存的极限。为了训练一个**万亿参数的模型，需要800个NVIDIA V100 GPU**，而这样的集群对大多数数据科学家来说根本无法实现。此外，以这样的规模训练模型需要复杂的并行技术组合，给数据科学家增加了重构模型的巨大负担。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在本论文中，我们提出了一种名为ZeRO-Infinity的新型异构系统技术，它利用GPU、CPU和NVMe内存，在有限资源下实现了**前所未有**的模型规模扩展，而无需对模型代码进行重构。同时，它实现了出色的训练吞吐量和可扩展性，不受限于有限的CPU或NVMe带宽。ZeRO-Infinity可以在当前一代GPU集群上容纳数**万亿甚至数百万亿个参数**的模型进行训练。它可以用于在单个NVIDIA DGX-2节点上微调万亿参数模型，使大型模型更易于使用。在训练吞吐量和可扩展性方面，它在512个NVIDIA V100 GPU上可以维持超过25 petaflops的性能（达到峰值的40%），同时还展示了超线性的可扩展性。ZeRO-Infinity的开源实现可通过DeepSpeed获得。
*注释：NVMe代表非易失性内存扩展（Non-Volatile Memory Express），是一种高性能、低延迟的存储接口协议。NVMe利用并行性和高带宽特性，提供了更高的I/O性能和更低的延迟。这使得NVMe成为处理大规模数据和高性能计算应用的理想选择，尤其在需要快速数据读写和响应时间的场景中。* <br>
*注释：DeepSpeed（https://www.deepspeed.ai/）是一个旨在使分布式训练变得简单、高效和有效的深度学习优化库。DeepSpeed已经被深度学习社区广泛采用。*

# 1 背景(EXTENDED)介绍
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;近年来，深度学习在取得巨大(tremendous)进展，使其成为我们生活中不可或缺的一部分，从为搜索引擎提供动力到智能家居虚拟助手。这些进展的核心在于模型规模的增加[1-3]，而多项研究表明这一趋势将会持续下去[4, 5]。因此，人们已经大量投资于训练庞大的模型。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在过去的三年中，深度学习中最大的训练密集模型的规模增长了1000倍，从一亿个参数（ELMo [6]）增长到超过一千亿个参数（GPT-3 [4]）。相比之下，单个GPU的内存仅增加了5倍（从16GB到80GB）。因此，模型规模的增长主要通过系统技术的进步来实现大规模深度学习模型的训练，其中包括模型并行化 [7]、流水线并行化 [8-10] 和 ZeRO [11, 12] 等并行技术，正在为训练更大、更强大的模型铺平道路.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当前大模型训练技术的sota技术是三维并行化(3D parallelism [13, 14])，它将模型（张量切片）并行化、流水线并行化和数据并行化相结合，有效地将深度学习训练扩展到数万亿个参数，并在数百或数千个GPU上进行。例如，DeepSpeed实现的三维并行化可以利用集群的GPU内存，使得在**800个NVIDIA V100 GPU上可以扩展到超过一万亿个参数的规模** [15]。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;尽管三维并行化(3D parallelism)在大型模型训练方面具有很大的能力，但我们现在正面临GPU内存墙的挑战 [16]。**集群的GPU内存简单地不足以支持模型规模的增长**。即使使用最新的NVIDIA A100 GPU，其具有80GB的内存，为了训练一个万亿参数的模型，三维并行化需要320个GPU才能容纳，而要扩展到未来百万亿参数级别的模型，则需要超过6K个GPU，即使我们假设未来几年GPU内存增加5倍。我们无法再依靠GPU内存作为瓶颈来维持模型规模的持续增长。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;GPU 内存墙也限制了数据科学家甚至无法访问当今的大型模型，特别是用于微调。大型模型首先在大量的通用数据上进行预训练，通过微调，同一模型可以针对各种应用进行专门优化。虽然对一个拥有数千亿个参数的模型进行预训练可能需要数百万个GPU计算小时，但进行微调的成本要低得多，只需要较少的GPU计算小时，并且可以在单个计算节点(不是单个gpu)上完成，使用少量的GPU。虽然许多企业和用户可以获得此类计算资源，但不幸的是，它们受限于计算节点上可用的内存，这进而限制了可以进行微调的模型规模。这使得**大型模型的微调对于大多数没有大规模GPU集群资源的研究人员和公司来说是无法实现的**。例如，即使单个DGX-2节点（16个GPU）具备足够的计算能力在合理的时间内对GPT-3进行微调，但要将模型适应于训练，需要超过8个DGX-2节点（128个GPU）并使用三维并行化。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;除了GPU内存墙外，用于训练大规模模型的最新技术在可用性和灵活性方面也存在限制。如上所述，三维并行化需要以复杂的方式将数据并行化、模型并行化和流水线并行化相结合，才能达到数千亿或数万亿个参数的规模。虽然这样的系统可能非常高效，但它要求数据科学家进行重大的模型代码重构，将单个GPU运算符替换为张量切片版本，并将模型分割成负载平衡的流水线阶段。这也使得三维并行化在支持的模型类型方面缺乏灵活性。具有复杂依赖关系的模型不能轻易转换为负载平衡的流水线结构。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;给定大型模型训练的现状，我们提出了三个问题：<br>
- 展望未来，我们如何支持模型规模的下一次1000倍增长，从拥有1750亿参数的模型（如GPT-3）到拥有数万亿参数的模型？<br>
- 我们如何让当今的大型模型对更多没有数百个GPU资源的数据科学家可用？<br>
- 我们能否通过消除模型重构和多种形式的并行化(parallelism)的需求，使大型模型训练更加简单？<br>
在本论文中，我们从三维并行化迈出了一大步，提出了ZeRO-Infinity，这是一种新颖的系统，能够解决大型模型训练的所有上述挑战。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**前所未有的模型规模**：ZeRO-Infinity通过新颖的异构内存访问技术——**无限卸载引擎（infinity offload engine）**，扩展了ZeRO技术家族[11, 12]。这使得ZeRO-Infinity能够利用CPU和NVMe内存同时支持有限的GPU资源上的大规模模型。此外，ZeRO-Infinity还引入了一种称为**内存中心平铺（memory-centric tiling）的新颖GPU内存优化技术**，以支持那些即使逐层单独加载也无法适应GPU内存的**极大尺寸的单个层**。通过无限卸载引擎和内存中心平铺技术，ZeRO-Infinity不仅支持模型规模的下一次1000倍增长，而且还使得拥有有限GPU资源的数据科学家能够使用大型模型。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;出色的训练效率：ZeRO-Infinity引入了一种新颖的数据分区策略，利用(leveraging)所有设备的聚合(aggregate)内存带宽，我们称之为**带宽中心分区(bandwidth-centric partitioning)**，并将其与**强大的通信重叠设计**以及在**无限卸载引擎**中进行**高性能NVMe访问**的优化相结合。尽管将数据卸载到CPU或NVMe，但ZeRO-Infinity提供了出色的训练效率，不受它们有限带宽的限制。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**易于使用**：有了ZeRO-Infinity，数据科学家不再需要根据三维并行化等多种并行化形式来调整他们的模型。这是由上面讨论的ZeRO-Infinity中的**内存中心平铺技术(memory-centric tiling)实现的**，该技术旨在减少单个大型层(layer)所需的GPU内存，否则需要模型并行化（张量切片）来适应GPU内存。此外，ZeRO-Infinity通过一种启发式易于实现的方法，自动化了训练任意模型架构所需的所有通信和数据分区，从而消除了手动模型代码重构的需要，即使在扩展到数万亿个参数时也是如此。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 本文的主要贡献如下：<br>
- 大型模型训练的内存和性能特征描述了不同组成部分的内存需求（第3节）以及训练的带宽需求（第4节），以确保训练的高效性。<br>
- ZeRO-Infinity（第5、6和第7节）是一种新颖的深度学习训练系统技术，包括五项创新技术，以解决内存和带宽需求，提供前所未有的模型规模，并且易于使用，同时实现出色的训练效率：**i) 无限卸载引擎**：充分利用现代集群上的异构架构，同时利用GPU、CPU和NVMe内存以及GPU和CPU计算能力。**ii) 内存中心平铺(memory-centric tiling)**：处理大规模运算符(超大数据层)，无需模型并行化。**iii) 带宽中心分区(bandwidth-centric partitioning)**：利用所有并行设备的聚合内存带宽。**iv) 重叠中心设计(overlap-centric design)**：将计算和通信重叠，提高效率。**v) 启发式实现**：避免模型代码重构，简化使用过程。<br>
- ZeRO-Infinity经过广泛(extensive)的评估，展示了以下内容：i) 在32个NVIDIA DGX-2节点（512个V100 GPU）上运行32万亿参数的前所未有的规模；ii) 在相同硬件上实现出色的训练效率，吞吐量超过25 petaflops( $10^{15}$ 一千万亿); iii) 兆(万亿)参数模型的超线性可扩展性；iv) 可访问性和易用性：在单个DGX-2节点上对万亿参数模型进行微调，无需使用任何模型并行化或模型代码重构；v) ZeRO-Infinity中不同技术对模型规模和效率的影响（第8节）。<br>
- 论文讨论了ZeRO-Infinity及其对未来硬件系统设计的潜在影响(在第9节)。
- 在DeepSpeed2中有一个ZeRO-Infinity的开源实现，DeepSpeed(https://www.deepspeed.ai/)是一个深度学习优化库，旨在使分布式训练变得简单、高效和有效，已经在深度学习社区广泛采用。



