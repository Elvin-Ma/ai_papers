# zero-infinity：打破极端规模(scale)深度学习模型的内存墙

# 摘要
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在过去的三年里，最大的密集深度学习模型的规模增长了1000倍以上，达到了数千亿个参数，而GPU内存只增长了5倍（从16GB到80GB）。因此，模型规模的增长主要是通过系统创新来支持的，这些创新使得大型模型可以适应多个GPU的总体内存。然而，我们接近了GPU内存的极限。为了训练一个万亿参数的模型，需要800个NVIDIA V100 GPU，而这样的集群对大多数数据科学家来说根本无法实现。此外，以这样的规模训练模型需要复杂的并行技术组合，给数据科学家增加了重构模型的巨大负担。
