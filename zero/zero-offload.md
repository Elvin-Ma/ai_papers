# ZeRO-Offload：普及十亿级模型训练

# 摘要
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;大规模模型训练一直是少数用户的专属领域，因为它通常需要进行复杂的模型重构，并且需要使用价格昂贵的GPU集群。ZeRO-Offload通过使大规模模型训练对几乎所有人都可用，改变了大模型训练的格局。**它可以在单个GPU上训练具有超过130亿参数的模型**，与流行框架如PyTorch相比，模型规模增加了10倍，并且在不需要数据科学家进行任何模型更改或牺牲计算效率(?)的情况下实现了这一点。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ZeRO-Offload通过将数据和计算卸载到CPU上，实现了大规模模型训练。为了保持计算效率，它被设计为最小化与GPU之间的数据移动，并减少CPU计算时间，同时最大限度地节省GPU上的内存。因此，相对于仅使用PyTorch训练一个**14亿参数**模型（在GPU上不会内存溢出的最大模型），ZeRO-Offload在单个NVIDIA V100 GPU上可以实现每秒**40 TFlops**的计算能力，而**PyTorch仅为30 TFlops**。当有多个GPU可用时，ZeRO-Offload还可以进行多GPU扩展，最多支持128个GPU的近线性加速。此外，它还可以与模型并行性一起工作，在单个DGX-2机器上训练具有超过700亿&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;参数的模型，相比之下,相对于仅使用模型并行增加了4.5倍的规模。<br>
通过将计算和内存效率与易用性相结合，ZeRO-Offload使大规模模型训练普及化，即使是只有单个GPU访问权限的数据科学家也可以使用。<br>

## 引言（Introduction）
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;自从2017年注意力机制的深度学习模型问世以来，我们见证了深度学习模型规模的指数级增长，这得益于这些基于注意力机制的模型在参数数量增加时所能提供的显著质量提升。例如，2017年，文献中最大的语言模型仅有不到1亿个参数。到了2018年，随着BERT的问世，这个数字增长到了超过3亿。而到了2019年，随着GPT-2、T5、Megatron-LM和Turing-NLG等模型的出现，模型规模增长到了数十亿级别。如今，最大的语言模型GPT-3拥有惊人的1750亿个参数。自2017年以来，模型规模增长了三个数量级，模型的准确度也随着模型规模的增加而提高。事实上，最近的研究表明，对于给定的准确度目标，较大的模型比较小的模型更具有资源效率。因此，我们预计未来模型的规模将继续增长。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;然而，由于当前系统技术的本质，大规模模型训练的可访问性严重受限。这些技术使得进入大规模模型训练领域成本高昂。具体来说，深度学习分布式并行训练技术，如管道并行化[10]、模型并行化[28]和ZeRO（零冗余优化器）[21]，通过将模型状态（参数、梯度和优化器状态）分布到多个GPU设备上，突破了单个GPU/加速器设备的内存限制，实现了原本无法适应单个GPU内存的大规模模型。所有破纪录的大型模型，如GPT-2、Megatron-LM、Turing-NLG和GPT-3，**都是使用上述技术的组合进行训练的**。然而，所有这些深度学习并行技术都需要足够数量的GPU设备，以便聚合的GPU内存可以容纳训练所需的模型状态(GPUS 显存之和要大于 模型状态所需显存)。例如，高效地训练一个具有100亿个参数的模型需要使用16个NVIDIA V100显卡的DGX-2等效节点，其成本超过10万美元，这已经超出了许多数据科学家、学术机构和工业机构的承受范围。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;异构深度学习训练是一种有希望的方法，通过利用CPU内存来减少GPU内存需求。在这个方向上已经做出了许多努力[8, 9, 11, 17, 23, 24, 32–34]。几乎所有这些努力都针对基于CNN的模型，其中激活内存是内存瓶颈，模型大小相对较小（小于500M）。然而，最近基于注意力机制的大规模模型训练的主要内存瓶颈是模型状态(model state)，而不是激活内存(activation)。现有文献中缺乏对于异构深度学习训练中这些工作负载的研究。此外，现有的异构训练方法在两个重要方面存在限制：i）几乎所有方法都利用CPU内存，但不利用CPU计算，而我们展示了**利用CPU计算可以显著减少CPU-GPU通信开销**；ii）它们大多数是为单个GPU设计和评估的[9, 11, 23, 34]，而在多个GPU上高效扩展的明确路径并不清晰，这对于大规模模型训练至关重要。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;针对上述限制，我们试图通过开发ZeRO-Offload来使大规模模型训练普及化，这是一种专门针对大规模模型训练的新型异构(heterogeneous)深度学习训练技术。ZeRO-Offload利用CPU内存和计算进行卸载(offload)，同时通过与基于ZeRO的数据并行技术[21]合作，提供了在多个GPU上高效扩展的明确路径。此外，我们的首要原则分析表明，ZeRO-Offload为大规模模型训练提供了一种优化的、唯一的最佳解决方案，可以在最大限度地节省内存的同时，最小化通信开销和CPU计算开销。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ZeRO-Offload的设计基于三个主要支柱：**i) 效率，ii) 可扩展性，和 iii) 可用性**。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**效率**：ZeRO-Offload中的卸载(offload)策略旨在实现与最先进的非卸载策略相当的计算效率，但适用于规模显著更大的模型。为了实现这个目标，我们依靠首要原则分析(principle analysis)来确定CPU和GPU设备之间的独特的最佳计算和数据分区策略。这个策略在三个关键方面是最优的：i) 与GPU相比，它在CPU上需要数量级更少的计算，防止CPU计算成为性能瓶颈；ii) 最小化CPU和GPU之间的通信量，防止通信成为瓶颈；iii) 可证明地在GPU上实现最大的内存节省，同时实现最小的通信量。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们的分析显示，在上述方面达到最优时，我们必须将**梯度、优化器状态和优化器计算卸载到CPU上**，同时保持**参数以及前向和反向计算在GPU上进行**。这种策略可以使模型大小增加10倍，同时实现最小的通信量和有限的CPU计算。这使得我们可以在单个NVIDIA V100 GPU上以40 TFLOPS的速度训练130亿个参数，而在相同的GPU上以12亿个参数只能达到30 TFLOPS，这是无需任何CPU卸载就能训练的最大模型。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;卸载优化器计算需要CPU执行O(M)的计算，而在GPU上执行O(MB)的计算(GPU上有分布式)，其中M和B分别是模型大小和批量大小。在大多数情况下，批量大小较大，CPU计算不是瓶颈，但对于小批量大小，CPU计算可能成为瓶颈。我们通过两种优化来解决这个问题：i) 一种高效的CPU优化器，比最先进的方法快6倍；ii) 一步延迟参数更新，允许将CPU优化器步骤与GPU计算重叠，同时保持准确性。它们共同确保了ZeRO-Offload即使在小批量大小下也能保持效率。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**可扩展性**：良好的可扩展性对于利用可能可用的**多个GPU**非常重要，这对于一些数据科学家来说至关重要。在深度学习社区中，数据并行通常被用作将深度学习训练扩展到多个GPU的事实标准[5, 26, 35]。然而，它并不是设计用于与异构训练配合使用，并且由于数据并行训练中数据和计算的复制，它面临着可扩展性方面的挑战。数据并行训练复制所有的模型状态，如优化器状态、参数和梯度，并且在每个GPU上复制优化器计算。因此，将模型状态或优化器计算卸载到CPU，并与数据并行结合使用，将导致大量的通信和CPU计算复制：CPU内存需求与数据并行程度成比例增加，同时由于增加的通信而限制吞吐量的可扩展性。<br>
*注释：上述cpu 指的是 多个数据并行模型副本*
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为了解决(address)这些挑战，ZeRO-Offload将独特的最佳卸载策略(optimal offload strategy)与基于ZeRO的数据并行相结合，而不是传统的数据并行。这种共生关系使得ZeRO-Offload能够在不考虑数据并行度的情况下，在CPU内存上维护优化器状态的**单个副本**。此外，它保持了GPU和CPU之间的总通信量以及CPU总计算的恒定，而不考虑数据并行性，使得ZeRO-Offload能够有效利用随着数据并行度增加而线性增加的CPU计算能力。因此，ZeRO-Offload在最多128个GPU上实现了出色的可扩展性。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;除了与基于ZeRO的数据并行相结合外，当有多个GPU可用时，ZeRO-Offload还可以与模型并行相结合[27, 28]，以实现更高的内存节省。<br>

![figure1](images/zero-offload-figure1.jpg)

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**可用性**：ZeRO-Offload作为开源PyTorch库DeepSpeed的一部分提供（www.deepspeed.ai）。与第2节讨论的大多数策略不同，ZeRO-Offload不需要对模型进行重构即可工作。实际上，PyTorch用户可以通过**对现有训练流程进行少量代码更改来启用ZeRO-Offload**，如图1所示，轻松训练10倍大的模型。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**贡献**：据我们所知，ZeRO-Offload是第一个完全分布式、基于CPU内存和计算资源的训练框架，用于训练大规模模型。我们总结其贡献如下：<br>

