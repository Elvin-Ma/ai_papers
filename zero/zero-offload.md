# ZeRO-Offload：普及十亿级模型训练

# 摘要
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;大规模模型训练一直是少数用户的专属领域，因为它通常需要进行复杂的模型重构，并且需要使用价格昂贵的GPU集群。ZeRO-Offload通过使大规模模型训练对几乎所有人都可用，改变了大模型训练的格局。**它可以在单个GPU上训练具有超过130亿参数的模型**，与流行框架如PyTorch相比，模型规模增加了10倍，并且在不需要数据科学家进行任何模型更改或牺牲计算效率(?)的情况下实现了这一点。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ZeRO-Offload通过将数据和计算卸载到CPU上，实现了大规模模型训练。为了保持计算效率，它被设计为最小化与GPU之间的数据移动，并减少CPU计算时间，同时最大限度地节省GPU上的内存。因此，相对于仅使用PyTorch训练一个**14亿参数**模型（在GPU上不会内存溢出的最大模型），ZeRO-Offload在单个NVIDIA V100 GPU上可以实现每秒**40 TFlops**的计算能力，而**PyTorch仅为30 TFlops**。当有多个GPU可用时，ZeRO-Offload还可以进行多GPU扩展，最多支持128个GPU的近线性加速。此外，它还可以与模型并行性一起工作，在单个DGX-2机器上训练具有超过700亿&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;参数的模型，相比之下,相对于仅使用模型并行增加了4.5倍的规模。<br>
通过将计算和内存效率与易用性相结合，ZeRO-Offload使大规模模型训练普及化，即使是只有单个GPU访问权限的数据科学家也可以使用。<br>

## 引言（Introduction）
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;自从2017年注意力机制的深度学习模型问世以来，我们见证了深度学习模型规模的指数级增长，这得益于这些基于注意力机制的模型在参数数量增加时所能提供的显著质量提升。例如，2017年，文献中最大的语言模型仅有不到1亿个参数。到了2018年，随着BERT的问世，这个数字增长到了超过3亿。而到了2019年，随着GPT-2、T5、Megatron-LM和Turing-NLG等模型的出现，模型规模增长到了数十亿级别。如今，最大的语言模型GPT-3拥有惊人的1750亿个参数。自2017年以来，模型规模增长了三个数量级，模型的准确度也随着模型规模的增加而提高。事实上，最近的研究表明，对于给定的准确度目标，较大的模型比较小的模型更具有资源效率。因此，我们预计未来模型的规模将继续增长。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;然而，由于当前系统技术的本质，大规模模型训练的可访问性严重受限。这些技术使得进入大规模模型训练领域成本高昂。具体来说，深度学习分布式并行训练技术，如管道并行化[10]、模型并行化[28]和ZeRO（零冗余优化器）[21]，通过将模型状态（参数、梯度和优化器状态）分布到多个GPU设备上，突破了单个GPU/加速器设备的内存限制，实现了原本无法适应单个GPU内存的大规模模型。所有破纪录的大型模型，如GPT-2、Megatron-LM、Turing-NLG和GPT-3，**都是使用上述技术的组合进行训练的**。然而，所有这些深度学习并行技术都需要足够数量的GPU设备，以便聚合的GPU内存可以容纳训练所需的模型状态(GPUS 显存之和要大于 模型状态所需显存)。例如，高效地训练一个具有100亿个参数的模型需要使用16个NVIDIA V100显卡的DGX-2等效节点，其成本超过10万美元，这已经超出了许多数据科学家、学术机构和工业机构的承受范围。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;异构深度学习训练是一种有希望的方法，通过利用CPU内存来减少GPU内存需求。在这个方向上已经做出了许多努力[8, 9, 11, 17, 23, 24, 32–34]。几乎所有这些努力都针对基于CNN的模型，其中激活内存是内存瓶颈，模型大小相对较小（小于500M）。然而，最近基于注意力机制的大规模模型训练的主要内存瓶颈是模型状态(model state)，而不是激活内存(activation)。现有文献中缺乏对于异构深度学习训练中这些工作负载的研究。此外，现有的异构训练方法在两个重要方面存在限制：i）几乎所有方法都利用CPU内存，但不利用CPU计算，而我们展示了**利用CPU计算可以显著减少CPU-GPU通信开销**；ii）它们大多数是为单个GPU设计和评估的[9, 11, 23, 34]，而在多个GPU上高效扩展的明确路径并不清晰，这对于大规模模型训练至关重要。<br>
