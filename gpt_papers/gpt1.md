# 通过生成式预训练提高语言理解能力

## 0. 摘要
自然语言理解包括各种各样的任务，如文本蕴涵、问题解答、语义相似性评估和文档分类。虽然大量的未标记的文本语料库非常丰富，但是用于学习这些特定任务的标记数据却非常稀缺，这就使得接受过判别训练的模型难以充分执行。我们证明，通过在不同的未标记文本语料库上生成语言模型的预训练，然后对每个特定任务进行区分性微调，可以实现这些任务的巨大收益。与以前的方法不同，我们在微调期间使用任务感知的输入转换，以实现有效的传输，同时对模型体系结构进行最小的更改。我们在自然语言理解的各种基准上证明了我们的方法的有效性。我们的一般任务不可知论模型优于使用专门为每项任务设计的体系结构的有区别训练的模型，在所研究的12项任务中，有9项任务显著提高了技术水平。例如，我们在常识推理（故事完形填空测试）上取得了8.9%的绝对改善，在回答问题（种族）上取得了5.7%的绝对改善，在文本继承（munli）上取得了1.5%的绝对改善。

## 1. 简介
有效地从原始文本中学习的能力对于减轻自然语言处理（NLP）中对监督学习的依赖至关重要。大多数深度学习方法需要大量手动标记的数据，这限制了它们在许多缺乏注释资源的领域中的适用性[61]。在这种情况下，那些可以利用未标记数据中的语言信息的模型提供了收集更多注释的宝贵替代方案，这既耗时又昂贵。此外，在可以考虑监督的那些情况中，以无监督的方式学习良好的表示也可以显著提高性能。迄今为止，最令人信服的证据是大量使用预先训练过的单词嵌入[10，39，42]来提高一系列NLP任务的性能[8，11，26，45]。

然而，利用来自未标记文本的单词级信息仍旧是一个挑战，这有两个主要原因。首先，不清楚哪种类型的优化目标在学习对传输有用的文本表示方面最有效。最近的研究着眼于各种目标，如语言建模[44]、机器翻译[38]和语篇连贯性[22]，每种方法在不同任务上都优于其他方法（https://gluebenchmark.com/leaderboard）。第二，对于将这些学习的表示转移到目标任务上的最有效方法，还没有达成共识。现有技术包括对模型体系结构进行特定于任务的更改[43，44]，使用复杂的学习方案[21]并添加辅助学习目标[50]。这些不确定性使得开发有效的语言处理半监督学习方法变得困难。

本文探索了一种结合无监督预训练和监督微调的半监督语言理解任务方法。我们的目标是学习一种通用的表示，这种表示经过很小的微调后可以适应各种任务。我们假设通过手动注释的训练示例（目标任务）访问大量未标记文本和多个数据集。我们的设置不要求这些目标任务与未标记的文集在同一个域中。我们采用两阶段训练程序。首先，我们使用未标记数据上的语言模型对象去学习神经网络模型的初始参数。随后，我们使用相应的监督目标对这些参数进行调整，1以适应目标任务。

对于我们的模型结构，我们 使用了Transformer[62]，它在机器翻译[62]、文档生成[34]和句法分析[29]等各种任务中都表现得很好。这个模型选项为我们提供了一个更加结构化的记忆方式来处理文本中的长期依赖关系，而不是像循环网络这样的替代方案，从而在不同的任务之间产生强大的迁移性能。在迁移过程中，我们 使用从traversal-style approaches方法[52]派生的特定于任务的输入自适应方法，该方法将结构化文本输入处理为单个连续序列。正如我们在实验中所证明的那样，这些调整使我们能够有效地进行微调，而对预先训练的模型的体系结构进行最小的更改。

我们评估了四种类型的语言理解任务——自然语言推理、问答、语义相似性和文本分类。我们的通用未知任务模型优于经过歧视性训练的模型，这些模型采用专门为每项任务设计的体系结构，在所研究的12项任务中有9项大大改进了最新技术。例如，我们在常识推理（故事完形测试）上取得了8.9%的绝对改善[40]，在回答问题（种族）上取得了5.7%的绝对改善[30]，在文本继承（multinli）上取得了1.5%的绝对改善[66]，在最近引入的粘合多任务基准上取得了5.5%的绝对改善[64]。我们还分析了预训练模型在四种不同环境下的零触发行为，并证明它为下游任务获得了有用的语义信息。

## 2. 相关工作
NLP的半监督学习。 我们的工作大体上属于自然语言半监督学习范畴。这种模式已经引起了人们的极大兴趣，已经应用于序列标记[24，33，57]或文本分类[41，70]等任务。最早的方法使用未标记的数据来计算单词级别或短语级别的统计信息，然后将这些统计信息用作受监督模型中的特征[33]。在过去的几年里，研究人员已经证明了使用单词嵌入[11，39，42]的好处，这些单词嵌入在未标记的语料库上进行训练，以提高在各种任务中的表现[8，11，26，45]。然而，这些方法主要是传递单词级别的信息，而我们的目标是捕获更高级别的语义。

最近的方法研究了从未标记的数据中学习和使用多个词级语义。短语级或句子级嵌入（可以使用未标记的语料库进行训练）已被用于将文本编码为适合各种目标任务的向量表示[28、32、1、36、22、12、56、31]。

**无监督的预训练**
无监督预训练是半监督学习的一种特殊情况，其 目标是找到一个好的初始点，而不是修改监督学习目标。早期的研究探索了该技术在图像分类[20，49，63]和回归任务[3]中的应用。随后的研究[15]表明，预训练作为一种正则化方案，能够在深层神经网络中实现更好的泛化。在最近的工作中，该方法被用来帮助训练深度神经网络的各种任务，如图像分类[69]、语音识别[68]、实体消歧[17]和机器翻译[48]。

最接近我们工作的是使用语言建模目标（language modeling objective）对神经网络进行预训练，然后在有监督的情况下对其进行微调。Dai[13]和Howard和Ruder[21]遵循此方法改进文本分类。然而，尽管预训练阶段有助于获取一些语言信息，但他们使用的LSTM模型限制了他们的预测能力，使其范围较短。相比之下，我们选择的transformer网络允许我们捕获更大范围的语言结构，如我们的实验所示。此外，我们还展示了我们的模型在更广泛的任务上的有效性，包括自然语言推理、释义检测和故事完成。其他方法[43、44、38]使用预先训练的语言或机器翻译模型中的隐藏表示（hidden representations）作为辅助功能，同时针对目标任务训练受监督模型。这涉及到每个单独目标任务的大量新参数，而在传输（transfer）过程中，我们需要对模型体系结构进行最小的更改。

**辅助训练目标**
增加辅助的无监督训练目标是半监督学习的一种替代形式。collobert和weston的早期工作[10]使用了各种各样的辅助NLP任务，如POS标记、分块、命名实体识别和语言建模，以改进语义角色标记。最近，REI[50]在目标任务目标中添加了一个辅助语言建模目标，并演示了序列标记任务的性能的提升。我们的实验也使用了一个辅助目标，但正如我们所展示的，无监督的预训练已经学习了与目标任务相关的几个语言方面。 增加辅助的无监督训练目标是半监督学习的一种替代形式。collobert和weston的早期工作[10]使用了各种各样的辅助NLP任务，如POS标记、分块、命名实体识别和语言建模，以改进语义角色标记。最近，REI[50]在目标任务目标中添加了一个辅助语言建模目标，并演示了序列标记任务的性能的提升。我们的实验也使用了一个辅助目标，但正如我们所展示的，无监督的预训练已经学习了与目标任务相关的几个语言方面。

## 3. Framework
我们的训练过程分为两个阶段。第一阶段是在大语料库上学习大容量语言模型。接下来是一个微调阶段，在这个阶段中，我们将使模型适应带有标签数据的特定任务。

### 3.1 Unsupervised pre-training
给定无监督tokens集合 $\mathcal{U}=\left\lbrace u_{1}, \ldots, u_{n}\right\rbrace$ , 我们使用标准语言模型目标（language modeling objective）来最大化以下似然函数：<br>
$$L_{1}(\mathcal{U})=\sum_{i} \log P\left(u_{i} \mid u_{i-k}, \ldots, u_{i-1} ; \Theta\right).^{(1)}$$ 
其中，k 是文本窗尺寸，条件概率 P 采用参数为 $\Theta$ 的神经网络建模。这些参数用SGD训练[15].
在我们的实验中，我们使用多层 Transformer decoder[34]作为语言模型，这是Transformer的变体[62]。该模型在输入上下文tokens上应用一个多头自注意操作(multi-headed self-attention operation)，随后是位置前馈层(position-wise feedforward layers)，以在目标tokens上生成一个输出分布:
$$\Theta h_{0}=U W_{e}+W_{p}$$    
$$h_{l}=transformer\_block\left(h_{l-1}\right) \forall i \in[1{} , n]       (2)$$
$$P(u)=softmax\left(h_{n} W_{e}^{T}\right)$$

其中 $\mathcal{U}=\left\lbrace u_{-k}, \ldots, u_{-1}\right\rbrace$ 是tokens的文本向量，n是网络层数， $W_{e}$ 是token嵌入矩阵(embedding matrix), $W_{p}$ 是位置嵌入矩阵。

### 3.2 Supervised fine-tuning
在用等式1中的目标对模型进行训练后，我们针对被监督目标任务调整这些参数。
