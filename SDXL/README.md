# SDXL: Improving Latent Diffusion Models (LDM) for High-Resolution Image Synthesis(图像合成)

# 摘要
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们介绍了SDXL，一种用于文本到图像合成的潜空间扩散模型(LDM)。与先前版本的稳定扩散相比，SDXL利用了一个**三倍大的UNet骨干**：模型参数增加主要是由于**更多的注意力块**和**更大的交叉注意力上下文**，因为SDXL使用了第二个文本编码器(总共使用了两个文本编辑器)。我们设计了多种新颖的条件方案，并在**多个宽高比**上对SDXL进行训练。我们还引入了一个改进模型(refinement model)，该模型使用事后图像到图像技术**改善**SDXL生成的样本的视觉保真度。我们证明了与先前版本的稳定扩散相比，SDXL显示出了显著提高的性能，并且在与最先进的黑盒图像生成器相比的结果上取得了竞争力。秉承促进开放研究和提高大型模型训练和评估透明度的精神，我们提供代码和模型权重的访问权限。<br>

# 1 引言
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;过去一年，在深度生成建模领域取得了巨大的突破，涵盖了各种数据领域，如自然语言[50]、音频[17]和视觉媒体[38, 37, 40, 44, 15, 3, 7]。在本报告中，我们专注于后者(视觉媒体)，并介绍了SDXL，这是稳定扩散的一个极大改进版本。稳定扩散是一种潜空间文本到图像扩散模型（DM），为近期的一系列进展提供了基础，例如3D分类[43]、可控图像编辑[54]、图像个性化[10]、合成数据增强[48]、图形用户界面原型设计[51]等。值得注意的是，应用范围非常广泛，涵盖了音乐生成[9]和从fMRI脑部扫描重建图像[49]等领域。<br>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;用户研究表明，SDXL在性能上始终明显超过(surpasses)了所有先前版本的稳定扩散（见图1）。在本报告中，我们介绍了导致性能提升的设计选择，包括：i）相比于先前的稳定扩散模型，使用了**3倍大的UNet骨干**（第2.1节）；ii）使用了两种简单而有效的**附加条件技术**（第2.2节），不需要任何形式的额外监督；iii）引入了一个独立的基于扩散的改进模型(refinement model)，该模型对SDXL生成的潜空间进行**噪声去噪处理**[28]，以提高其样本的视觉质量（第2.5节）。<br>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在视觉媒体创作领域，一个主要关注点是，虽然黑盒模型(black-box-models)通常被认为是最先进的，但其架构的不透明性阻碍了对其性能的准确评估和验证。这种缺乏透明度影响了可重现性，阻碍了创新，并阻止了社区在这些模型的基础上进行进一步的科学和艺术进展。此外，这些闭源策略使得以公正客观的方式评估这些模型的偏见(bias)和局限性变得具有挑战性，这对于它们的负责任和道德部署至关重要。通过SDXL，我们发布了一个开放模型，其性能与黑盒图像生成模型(eg: midjourney)具有竞争力（见图10和图11）。<br>

# 2 提升稳定扩散
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在本节中，我们介绍了我们对稳定扩散架构的改进。这些改进是**模块化的**，可以单独或一起使用来扩展任何模型。尽管以下策略是作为潜空间扩散模型（LDMs）[38]的扩展实现的，但它们中的大多数**也适用于像素空间**的对应模型。<br>

![figure1](images/SDXL-figure1.jpg)

## 2.1 架构与规模
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从Ho等人的开创性工作[14][DDPM](https://arxiv.org/pdf/2006.11239.pdf)和Song等人的工作[47]开始，它们证明了DM对于图像合成是强大的生成模型，Convolution UNet[39](https://arxiv.org/pdf/1505.04597.pdf)架构一直是基于扩散的图像合成的主导架构。然而，随着基础DM的发展[40, 37, 38]，底层架构不断演化：从添加自注意力和改进的上采样层[5](https://arxiv.org/pdf/2105.05233.pdf)，到用于文本到图像合成的交叉注意力[38](https://arxiv.org/pdf/2112.10752.pdf)，再到纯Transformer-based架构[33](https://arxiv.org/pdf/2212.09748.pdf)。<br>






