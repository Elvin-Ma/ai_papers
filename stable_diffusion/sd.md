# High-Resolution-Image-Synthesis-with-Latent-Diffusion-Models(stable-diffusion) 高分辨率图像合成与潜在扩散模型

# 摘要
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过将图像形成过程分解为去噪自动编码器的顺序应用，扩散模型（DMs）在图像数据及其他领域上实现了最先进的合成结果。此外，它们的构造允许引入**指导机制**以控制图像生成过程而无需重新训练。然而，由于这些模型通常直接在像素空间中操作，优化强大的DMs往往需要消耗数百个GPU天的时间，而inference由于顺序评估而变得昂贵。为了在有限的计算资源上进行DM训练并保持其质量和灵活性，我们将它们应用于强大的预训练自动编码器的潜在空间。与以前的工作相比，训练扩散模型在这样的表示上首次实现了在复杂性降低和细节保留之间接近最优点的目标，极大地提高了视觉保真度。通过在模型架构中引入交叉注意力层，我们将扩散模型转化为强大而灵活的生成器，可以接受文本或边界框等通用条件输入，并以卷积方式实现高分辨率合成。我们的潜在扩散模型（LDMs）在图像修复和类条件图像合成方面取得了新的最先进成绩，并在各种任务上表现出极具竞争力的性能，包括文本到图像合成、无条件图像生成和超分辨率，同时与基于像素的DMs相比，显著降低了计算要求。<br>

# 1 引言
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;图像合成(Image synthesis)是计算机视觉领域中最近发展最引人注目的领域之一，但也是计算需求最大的领域之一。特别是对于复杂自然场景的高分辨率合成，目前主要通过扩展基于似然的模型来实现，这些模型可能包含数十亿个参数的自回归（AR）变换器[66,67]。相比之下，GAN（生成对抗网络）[3, 27, 40]的有希望结果主要局限于具有相对有限变化性的数据，因为它们的对抗学习过程**不容易**扩展到建模复杂的多模态分布。最近，扩散模型[82]，由一系列去噪自编码器构建而成，在图像合成[30,85]以及其他领域[7,45,48,57]上取得了令人印象深刻的结果，并在类别条件图像合成[15,31]和超分辨率[72]方面定义了最先进的水平。此外，即使是**无条件的扩散模型**也可以轻松应用于修复和着色等任务[85]，或者基于笔划的合成[53]，而其他类型的生成模型[19,46,69]则不行。作为基于似然的模型，它们不会出现GAN的模式崩溃和训练不稳定问题，并且通过充分利用参数共享，它们可以模拟高度复杂的自然图像分布，而无需像AR模型[67]那样涉及数十亿个参数。<br>

**民主化高分辨率图像合成** 扩散模型属于基于似然的模型类别，其模式覆盖行为使其倾向于在建模数据的不可感知细节上消耗过多的容量（因此需要计算资源）[16, 73]。尽管重新加权的变分目标[30]旨在通过对初始去噪步骤进行欠采样来解决这个问题，但扩散模型仍然需要大量的计算资源，因为在RGB图像的高维空间中训练和评估这样的模型需要重复的函数评估（和梯度计算）。例如，训练最强大的扩散模型通常需要数百个GPU天（例如，在[15]中需要150-1000个V100天），在噪声版本的输入空间上进行重复评估也使得推理变得昂贵，因此生成5万个样本需要大约5天[15]在单个A100 GPU上。这对于研究界和普通用户有两个影响：首先，训练这样的模型需要大量的计算资源，只有少部分领域内的人才能够获得，并且会留下巨大的碳足迹[65, 86]。其次，评估已经训练好的模型在时间和内存方面也很昂贵，因为同一模型架构必须按顺序运行大量步骤（例如，在[15]中是25-1000步）。<br>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为了增加这个强大模型类的可访问性，同时减少其显著的资源消耗，需要一种方法来降低训练和采样的计算复杂度。因此，**降低扩散模型的计算需求而不损害其性能**对于提高其可访问性至关重要。<br>

**转向潜空间**  我们的方法始于对已经训练好的扩散模型在像素空间的分析：图2展示了一个训练好的模型的失真率权衡。与任何基于似然的模型一样，学习可以大致分为两个阶段：首先是感知压缩阶段，该阶段去除高频细节但仍学习了少量语义变化。在第二阶段，实际的生成模型学习了数据的语义和概念组合（语义压缩）。因此，我们的目标是首先找到一个感知等效但计算上更合适的空间，在该空间中我们将训练用于高分辨率图像合成的扩散模型。<br>







- [论文链接](https://arxiv.org/pdf/2112.10752.pdf)
