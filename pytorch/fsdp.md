# PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel（在完全分片数据并行上的扩展经验）

# 摘要
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;众所周知，大型模型在各个领域都有潜在的优越性能。尽管机器学习系统研究领域取得了显著进展，使得大型模型的开发和探索成为可能，但**这些能力仍然仅限于少数高级用户和行业领导者**，从而为广大社区访问和利用这些技术设置了一道隐形的技术壁垒。本文介绍了PyTorch完全分片数据并行（FSDP）作为大型模型训练的行业级解决方案。FSDP与PyTorch的几个关键核心组件（包括张量实现、调度系统(dispatcher system)和CUDA内存缓存分配器）密切协同设计，以提供非侵入式(non-intrusive)的用户体验和高效的训练效率。此外，FSDP还原生地融合了一系列技术和设置，以优化各种硬件配置下的资源利用。实验结果表明，FSDP能够在TFLOPS方面实现与**分布式数据并行(DDP)相当的性能**，同时支持显著更大的模型，并具有近线性的可扩展性。<br>

*(代码：https://github.com/pytorch/pytorch/blob/main/torch/distributed/fsdp/fully_sharded_data_parallel.py/.）*

# 1 引言
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;神经网络模型的规模正在以前所未有的速度增长，为各个领域的突破提供了便利。在问世之初，具有 1750 亿参数的 GPT-3 [3] 模型在几乎所有自然语言处理任务中创下了新纪录。构建在 GPT 模型之上的产品应用 [23] 迅速展示了它们改变整个行业的潜力。现代大规模推荐模型 [19, 33] 可以超过 1 万亿个参数，其中包括快速增长的密集层组件。这些模型驱动着每天为数十亿用户提供服务的应用程序。随着大型神经网络不断突破科学和技术的限制，一种工业级工具能够以高效的方式简化这些模型的训练，将有助于加快进展的速度。<br>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;近年来，学术界引入并研究了许多先进的方法来扩大神经网络模型。管道并行性 [6, 8, 11, 15, 20] 将一个模型实例划分为多个阶段，并将这些阶段分布在多个设备上，激活值和梯度在阶段之间进行通信。张量并行性 [9, 21, 31, 32] 对模型参数进行分片，对每个设备进行部分计算，并在所需的层边界进行激活值的通信。零冗余并行性 [27, 28, 30] 也对参数进行分片，但按需通信参数以恢复其未分片的形式，并在每个设备上执行模型。上述技术作为实现在各种应用中训练大型神经网络的基本构建块。然而，仍然存在两个挑战。首先，其中一些方法与特定的模型架构紧密集成，限制了它们作为训练大型模型的**通用解决方案**的使用。其次，其中一些技术是基于不断演进的底层机器学习框架的内部接口构建的，这使得它们容易受到框架实现的变化的影响。因此，与机器学习框架的核心功能共同设计一个本地解决方案更加稳健和高效。此外，以**可组合和可定制的方式**构建这样的解决方案还有可能促进学术界未来的创新。<br>



