# PyTorch Distributed: Experiences on Accelerating Data Parallel Training

摘要
本文介绍了PyTorch分布式数据并行模块的设计、实现和评估。PyTorch是一个广泛采用的科学计算包，用于深度学习研究和应用。深度学习的最新进展表明大型数据集和大型模型的价值，这需要能够将模型训练扩展到更多的计算资源上。数据并行性已经成为分布式训练的流行解决方案，因为它具有直观的原理和广泛的适用性。一般而言，分布式数据并行技术在每个计算资源上复制模型，独立生成梯度，然后在每次迭代中通信这些梯度以保持模型副本的一致性。尽管这种技术在概念上很简单，但计算和通信之间的微妙依赖关系使得优化分布式训练效率变得非常复杂。从v1.5版本开始，PyTorch本地提供了多种技术来加速分布式数据并行，包括梯度分桶、计算与通信的重叠以及跳过梯度同步等。评估结果表明，适当配置时，PyTorch分布式数据并行模块在使用256个GPU时实现了近线性的可扩展性
