# PyTorch Distributed: Experiences on Accelerating Data Parallel Training

# 摘要
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;本文介绍了PyTorch分布式数据并行模块的设计、实现和评估。PyTorch是一个广泛采用的科学计算包，用于深度学习研究和应用。深度学习的最新进展表明大型数据集和大型模型的价值，这需要能够将模型训练扩展到更多的计算资源上。数据并行性已经成为分布式训练的流行解决方案，因为它具有直观的原理和广泛的适用性。一般而言，分布式数据并行技术在**每个计算资源上复制模型**，独立生成梯度，然后在每次迭代中通信这些梯度以保持模型副本的一致性。尽管这种技术在概念上很简单，但**计算和通信之间的微妙依赖关系使得优化分布式训练效率变得非常复杂**。从v1.5版本开始，PyTorch本地提供了多种技术来加速分布式数据并行，包括**梯度分桶、计算与通信的重叠以及跳过梯度同步**等。评估结果表明，适当配置时，PyTorch分布式数据并行模块在使用256个GPU时实现了近线性的可扩展性.<br>

# 1 引言
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;深度神经网络（DNN）已经为各种应用提供了动力，包括图像识别[20]、语言翻译[15]、异常检测[16]、内容推荐[38]、药物发现[33]、艺术生成[28]、游戏玩法[18]和自动驾驶汽车[13]等。许多应用通过使用更大的模型和更大的数据集来优化以追求更高的智能，这需要分布式训练系统的进一步发展。在现有的解决方案中，分布式数据并行是一种主导策略，因为它对系统的**干扰最小**。本文介绍了PyTorch v1.5中分布式数据并行包的设计、实现和评估。<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;训练DNN模型通常需要反复进行三个步骤[26]：前向传播计算损失，反向传播计算梯度，以及优化器步骤更新参数。数据并行性的概念普遍适用于这样的框架。应用程序可以创建多个模型副本，每个模型副本都在一部分训练数据上工作，并**独立执行前向传播和反向传播**。然后，模型副本可以根据算法同步它们的梯度或更新的参数。在应用程序端纯粹构建一个可工作的数据并行版本理论上是可能的，因为它只需要在每次迭代中插入适当的通信。然而，为了挤出最后一丝性能，需要在设计和调优上投入大量的工作。在平台端提供本地的分布式数据并行API可以帮助应用程序开发人员专注于优化他们的模型，而平台开发团队可以持续透明地提高训练速度。提供一个通用的分布式数据并行包面临三个挑战。<br>
- **数学等价性**：数据并行的目的是加速在**大型数据集**上的训练。应用程序期望获得与在没有模型复制的情况下进行本地训练时相同的结果模型。这要求尽管是分布式的，但**在数学上等价于本地训练**。
- **非侵入性和拦截式API**：应用程序开发通常从本地模型开始，然后在需要时扩展。为了避免在过渡期间出现巨大的困难，API必须对应用程序代码**非侵入性**。另一方面，API需要允许内部实现及时拦截信号以进行通信和系统优化。
- **高性能**：数据并行训练受到计算和通信之间微妙依赖关系的影响。设计和实现必须探索解决方案空间，以将更多资源高效地转化为更高的训练吞吐量。
- 
